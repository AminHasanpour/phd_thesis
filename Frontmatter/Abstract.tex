\section*{English Abstract}
\addcontentsline{toc}{section}{English Abstract}

The rapid growth of \gls{ml} and \gls{dl} has enabled increasingly capable intelligent systems, yet deploying such models on resource-constrained embedded devices remains a major challenge. \Gls{tinyml} addresses this challenge by enabling efficient on-device inference, offering benefits in latency, privacy, energy consumption, and robustness in low-connectivity environments. However, the \gls{tinyml} ecosystem is highly fragmented, spanning heterogeneous hardware platforms, diverse software toolchains, and varying deployment workflows, which complicates tool selection, model optimization, and large-scale adoption in industrial contexts.

This thesis investigates the deployment of \gls{ml} models on embedded devices, with a focus on practical efficiency and adoption in industrial applications. First, a comparative study of cavitation detection in industrial pumps illustrates the complexity of decision-making by showing that traditional \gls{ml} approaches such as Support Vector Machines can outperform or rival \gls{dl} models when paired with suitable feature engineering, while also highlighting the importance of benchmarking models directly on target hardware. Second, the thesis introduces \textit{EdgeMark}, a modular automation and benchmarking framework for embedded AI tools that streamlines model conversion, deployment, and evaluation across heterogeneous TinyML platforms. EdgeMark enables systematic comparison of toolchains and reveals practical limitations and performance trade-offs. Third, a detailed survey of quantization techniques in embedded AI toolchains provides an analytical overview of supported quantization schemes, hardware compatibility, and workflow characteristics, offering engineers actionable guidance for selecting suitable deployment pipelines.

Together, these contributions advance the understanding of TinyML deployment strategies, clarify the capabilities and constraints of current embedded AI tools, and support more informed, future-proof decision-making for researchers and practitioners working with \gls{ml} on resource-constrained devices.

\newpage
\section*{Dansk Abstrakt}
\addcontentsline{toc}{section}{Dansk Abstrakt}

Den hurtige vækst inden for \gls{ml} og \gls{dl} har muliggjort stadig mere kapable intelligente systemer, men udrulning af sådanne modeller på ressourcebegrænsede, indlejrede enheder udgør fortsat en væsentlig udfordring. \Gls{tinyml} adresserer denne udfordring ved at muliggøre effektiv inferens direkte på enheden og tilbyder fordele i form af lavere latenstid, forbedret privatliv, reduceret energiforbrug samt øget robusthed i miljøer med begrænset netværksforbindelse. \gls{tinyml}-økosystemet er imidlertid stærkt fragmenteret og spænder over heterogene hardwareplatforme, forskellige softwareværktøjskæder og varierende arbejdsgange for udrulning, hvilket komplicerer værktøjsvalg, modeloptimering og storskala anvendelse i industrielle sammenhænge.

Denne afhandling undersøger udrulning af \gls{ml}-modeller på indlejrede enheder med fokus på praktisk effektivitet og anvendelse i industrielle applikationer. For det første illustrerer et komparativt studie af kavitationsdetektion i industrielle pumper kompleksiteten i beslutningstagning ved at vise, at traditionelle \gls{ml}-tilgange såsom Support Vector Machines kan overgå eller matche \gls{dl}-modeller, når de kombineres med hensigtsmæssig feature engineering, samtidig med at studiet fremhæver vigtigheden af at benchmarke modeller direkte på mål-hardware. For det andet introducerer afhandlingen \textit{EdgeMark}; et modulært automations- og benchmarking-framework for indlejrede AI-værktøjer, som forenkler modelkonvertering, udrulning og evaluering på tværs af heterogene TinyML-platforme. EdgeMark muliggør systematisk sammenligning af værktøjskæder og afdækker praktiske begrænsninger og performance-trade-offs. For det tredje præsenterer afhandlingen et detaljeret survey af kvantiserings teknikker i indlejrede AI-værktøjskæder, som giver et analytisk overblik over understøttede kvantiseringsskemaer, hardwarekompatibilitet og arbejdsgangskarakteristika, og dermed tilbyder ingeniører handlingsrettet vejledning i valg af egnede udrulnings-pipelines.

Samlet set bidrager disse resultater til en dybere forståelse af TinyML-udrulningsstrategier, tydeliggør kapabiliteter og begrænsninger i nutidens indlejrede AI-værktøjer samt understøtter mere velinformeret og fremtidssikret beslutningstagning for forskere og praktikere, der arbejder med \gls{ml} på ressourcebegrænsede enheder.
