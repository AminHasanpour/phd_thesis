\chapter{Conclusions and Future Directions}\label{ch:conclusion}

This thesis investigated the challenges and opportunities associated with deploying machine learning models on resource-constrained embedded systems, a field commonly referred to as \gls{tinyml} or \gls{eai}. Motivated by the rapid industrial adoption of \gls{ai} and the simultaneous proliferation of heterogeneous embedded platforms, this work aimed to provide both practical solutions and systematic insight into a fragmented and rapidly evolving ecosystem. Through a combination of applied case studies, tooling contributions, and comparative analyses, the thesis contributes to a deeper understanding of how \gls{ml} models can be efficiently deployed on embedded devices.

\section{Summary of Contributions}

The thesis is structured around three complementary research contributions, each presented in a separate paper. Collectively, these contributions address key aspects of the \gls{tinyml} deployment pipeline, from model selection and evaluation to tooling and quantization strategies.

\textbf{Paper A} demonstrated that effective embedded intelligence does not necessarily require complex \gls{dl} models. Using pump cavitation detection as a real-world industrial case study, the paper showed that traditional \gls{ml} techniques, specifically \glspl{svm}, can achieve competitive performance when combined with careful feature engineering and appropriate problem formulation. At the same time, \glspl{cnn} were shown to offer increased flexibility and generalization capability. A key outcome of this work was the demonstration that benchmarking models on target hardware is essential, as theoretical efficiency metrics do not always reflect practical performance once software stacks and hardware characteristics are considered.

\textbf{Paper B} addressed the systemic challenges arising from the fragmentation of the \gls{tinyml} ecosystem. Through a review of existing \gls{eai} tools and frameworks, the paper highlighted significant differences in supported features, usability, and performance characteristics. Building on this analysis, the EdgeMark system was introduced as an open-source automation and benchmarking framework designed to orchestrate model generation, conversion, deployment, and evaluation across diverse toolchains and hardware platforms. By embracing heterogeneity rather than enforcing uniformity, EdgeMark enables reproducible and fair comparisons of \gls{eai} tools, lowering the barrier to informed tool selection and adoption.

\textbf{Paper C} focused on quantization, one of the most critical enabling techniques for \gls{tinyml} deployments. The paper surveyed twelve widely used \gls{eai} toolchains, comparing their supported quantization strategies, deployment workflows, and hardware compatibility. The resulting taxonomy and comparison tables provide a practical reference for developers and researchers seeking to align quantization approaches with application requirements and device constraints. In addition, the paper discussed emerging trends and unresolved challenges in quantization, including mixed-precision approaches, tooling transparency, and the gap between research-oriented methods and production-ready solutions.

The findings of this thesis highlight a fundamental tension at the core of \gls{tinyml}: the coexistence of highly abstract \gls{ml} models with deeply constrained embedded hardware. While fragmentation across hardware platforms and software toolchains introduces significant complexity, it also enables innovation and application-specific optimization. The results suggest that progress in \gls{tinyml} will depend less on identifying a single dominant tool or framework, and more on developing methodologies and systems that allow practitioners to reason systematically about trade-offs in accuracy, latency, memory usage, and energy consumption.

From an industrial perspective, this work underscores the importance of hardware-aware evaluation and toolchain selection. For academic research, it emphasizes the need to complement algorithmic advances with realistic deployment studies and reproducible benchmarks. By providing open-source tooling and empirical evaluations, this thesis aims to help bridge the gap between research prototypes and deployable \gls{eai} systems.

\section{Future Research Directions}

While this thesis addressed several key challenges in \gls{tinyml}, it also opens multiple avenues for future research:

\begin{itemize}
    \item \textbf{Expanding EdgeMark:} \gls{tflm}, for example, has attempted to serve as a unifying framework for \gls{tinyml} deployment by providing a solid backbone for integrating multiple vendors' execution kernels. Edge Impulse extends \gls{tflm} by adding a much better user interface, additional features, and its own model conversion engine. Although these are valuable efforts, each initiative follows its own development path and does not fully account for the diversity of the \gls{tinyml} ecosystem. This suggests that higher-level orchestration frameworks such as EdgeMark may have an enduring role to play. Future work could extend EdgeMark to support a broader range of hardware platforms, including emerging accelerators and novel microcontroller architectures. Furthermore, integrating additional toolchains would enhance its value as a comprehensive and reproducible benchmarking platform.

    \item \textbf{AutoML and EdgeMark:} Deployment systems such as EdgeMark could help \gls{automl} frameworks by incorporating real deployment-time metrics directly into the model search and optimization process. This would enable the automatic discovery of models that are not only accurate in theory, but also efficient and practical on specific embedded hardware platforms.

    \item \textbf{Quantization standards and tooling:} Quantization is one of the most effective techniques in \gls{tinyml}, yet it can be implemented in many different ways. Although \gls{onnx} has become a popular format for \gls{ml} models, its support for quantization remains limited: only a small subset of quantization methods is implemented, and even its CPU execution backend does not fully support all quantized operators. At present, QKeras provides researchers with extensive flexibility for designing quantized models, but the absence of a common representation for such models disconnects it from deployment toolchains. Future research could therefore focus on developing standardized representations and tool support for advanced quantization techniques within widely adopted formats such as \gls{onnx}.

    \item \textbf{A platform for TinyML}: In Chapter~\ref{ch:introduction}, several model and system-level optimization techniques relevant to \gls{tinyml} were explained. However, many of these techniques, including \gls{automl}, compression, neuron merging, and knowledge distillation, are not yet implemented in existing \gls{tinyml} toolchains. This limits their practical adoption and reduces the impact of research contributions in the field. Creating a unified platform that integrates state-of-the-art \gls{tinyml} techniques could significantly benefit both researchers and practitioners by lowering the barrier to experimentation and real-world deployment.
\end{itemize}

\section{Final Remarks}

\Gls{tinyml} represents a crucial step toward ubiquitous \gls{ai} by enabling intelligent processing directly at the edge where data is generated. This thesis contributes to that vision by clarifying the design space, exposing practical trade-offs, and providing tools to manage complexity rather than obscure it. By embracing heterogeneity and grounding \gls{ml} techniques in real deployment constraints, this work supports the development of efficient, trustworthy, and sustainable \gls{eai} systems.
